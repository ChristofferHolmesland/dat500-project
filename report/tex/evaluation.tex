In this section, we are going to look at the difference in runtime between the implementation in Python and the Spark implementation. We are also going to show the results of some search queries.

\subsection{Experimental setup}

The MRJob/Spark implementation code ran on the Hadoop cluster described in the Hadoop cluster section. The Python implementation ran on a machine running Windows 10 Pro with the following hardware: Intel i5-8600K 3.6GHz CPU, 16 GB DDR4 2667MHz memory, and a SSD disk with a read speed of 500MB/s and a write speed of 320MB/s. The Python version used is 3.7.4 64-bit. To measure the execution time of the pre-processing scripts we used the time(1)\cite{Time1} linux command. To be able to use linux commands on a Windows machine, we used the Git Bash terminal\cite{GitBash}. In the pre-processing steps each task is implemented in MRJob except the graph task which was implemented in Spark. The algorithm steps are implemented using Spark. The time unit is seconds unless otherwise specified. To measure the execution time, we used the time function from the time library in Python. We were not able to use the time(1) command because we wanted to measure several functions defined in the same script

\subsection{Results}

\subsubsection{Pre-processing}

As shown in the table \ref{tab:preprocess runtime} there is a significant difference between the implementations. The Python implementation is about 3.5 times faster than the implementation running on Hadoop. There are three main reasons for why the difference is so large.
 
The first and most important one is that there is an overhead when you use Hadoop. The time to connect and actually start the job is typically between 45 and 60 seconds. This means that since six tasks are executed the overhead could be as much as 360 seconds which is almost as much as the total time of the Python implementation. 

The second reason for why the Python implementation is faster is because all of the data is able to fit in memory at once, while the Hadoop implementation requires data to be stored on multiple nodes and transferred between them. 

The third reason is because the machine running the Python code is faster, it has more memory and a faster processor. Since the pre-processing is only supposed to happen once, we decided to not spend a lot of time optimizing the code so that we could focus on the algorithm instead.

\begin{table}[H]
\centering
    \begin{tabular}{ |c|c|c| } 
        \hline
        \textbf{Task} & \textbf{Python} & \textbf{MRJob / Spark} \\ 
        \hline
        name\_basics & 25.5 & 102.3 \\ 
        title\_basics & 17.5 & 89.6 \\
        title\_principals & 32.9 & 664.3 \\ 
        title\_ratings & 2.0 & 67.0 \\ 
        graph & 106.6 & 205.3 \\ 
        genre\_score & 195.2 & 232.3 \\ \hline
        \textbf{Total} & \textbf{379.7} & \textbf{1360.8} \\ 
        \hline
    \end{tabular}
    \caption{Pre-processing runtime of Python and Spark in seconds}
    \label{tab:preprocess runtime}
\end{table}

\subsubsection{Algorithm}

The search query execution times were measured while using the attributes from the Interstellar movie, shown in section \ref{sec:appendixA}, Appendix A - Search results. The total Python time is an estimate based on the relation score measurement. The relation score times are reported as a per relation score to better reflect the difference. The reason for why the difference is so great is because the Spark implementation is able to compute multiple relation scores at the same time, while the Python implementation can only compute one. A more detailed explanation of the difference can be found in the Relation score section in part 5. In the execution time of the algorithm we can again see that when transferring data between nodes is required the time increases a lot. This is why the Python implementation is faster in the candidate actors task and the similarity score task. As we discussed in the similarity score section we were not able to figure out a good method of sharing the Tensorflow model between the worker nodes on Spark which is why the time is significantly greater in this task. The relation score time was calculated while running a 2-step search. When the number of steps is increased to three the run time per relation is increased to 0.4 seconds. The difference between the Interstellar search with 3 actors and 5 actors is caused by the fact that the number of groups is much larger when five candidate lists are used. Instead of 2700 groups there are about 24 million.


\begin{table}[H]
	\centering
    \begin{tabular}{ |c|c|c|c| } 
        \hline
        \textbf{Task} & \textbf{Python} & \textbf{Spark 3 actors} & \textbf{Spark 5 actors}\\ 
        \hline
        candidate actors & 60.3 & 331.5 & 344.7 \\ 
        similarity score & 89.6 & 448.8 & 461.4 \\ 
        relation score & 438.0 & 0.0362 & 0.0254 \\ \hline
        \textbf{Total} & \textbf{13.7 days} & \textbf{1182.1} & \textbf{2388.7} \\ 
        \hline
    \end{tabular}
	\caption{Algorithm runtime of Python and Spark in seconds}
	\label{tab:algorithm runtime}
\end{table}


\subsubsection{Search result}

The search engine is not limited to five groups for a search query. It will return groups using the top 30 actors from each candidate list, and also return the complete candidate list for each query. A more complete search result is shown in Section \ref{sec:appendixA}, Appendix A - Search result. The following tables are the top five groups from two search queries. It is also possible to have queries where the number of actors is not three. 



\begin{table}[H]
\centering
    \begin{tabular}{ |c|c|c|c| } 
        \hline
        \textbf{Actor 1} & \textbf{Actor 2} & \textbf{Actor 3} & \textbf{Score} \\ 
        \hline
        nm0000190 & nm0004266 & nm1567113  & 9.145267 \\ 
        nm0000190 & nm0544718 & nm1567113  & 8.54046 \\ 
        nm0000354 & nm0004266 & nm1567113  & 8.534471 \\ 
        nm0000190 & nm0004266 & nm1325419  & 8.496985 \\ 
        nm0000190 & nm0004266 & nm0000234  & 8.451193 \\ 
        \hline
    \end{tabular}
	\caption{Interstellar attributes with a 3-step relation score search}
	\label{tab:3-step relation score}
\end{table}



The original actors from the Interstallar movie are Matthew McConaughey: nm0000190, Anne Hathaway: nm0004266, Jessica Chastain: nm1567113. As the result show we achieved our goal of getting the original cast highly ranked by the engine.

However, it also highlights the largest problem we have been struggling to solve, which is that groups often contain the same actors. In this result the original actor from the second candidate list is the recommendation for eight of the top ten groups. The first candidate is repeated less, only four times in the top ten groups.



\begin{table}[H]
	\centering
    \begin{tabular}{ |c|c|c|c| } 
        \hline
        \textbf{Actor 1} & \textbf{Actor 2} & \textbf{Actor 3} & \textbf{Score} \\ 
        \hline
        nm2633535 & nm1126657 & nm1107001  & 6.8459167 \\ 
        nm2633535 & nm1126657 & nm0941777  & 6.8427186 \\ 
        nm3836977 & nm2056274 & nm2356421 & 6.8229513 \\ 
        nm2633535 & nm1126657 & nm1212722  & 6.8178062 \\ 
        nm2633535 & nm1126657 & nm1310016  & 6.790106 \\ 
        \hline
    \end{tabular}
\caption{1917 attributes with a 2-step relation score search}
\label{tab:2-step relation score}
\end{table}



The only original actor present in the result is George MacKay: nm1126657. Our initial thought was that the other actors must not be very good which turned out not to be true because both of them have acted in titles like Game of Thrones and Star Wars. The reason is that their birth year is missing from the data. This means that the engine is not able to consider them as candidates because their age cannot be determined.