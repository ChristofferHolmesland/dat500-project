{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates the relationship between {}_actors.tsv\n",
    "# Requires all {}_actor.tsv files, principals.tsv, input.txt\n",
    "# Outputs into final.tsv\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import ast\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import ast\n",
    "import glob\n",
    "import itertools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e3fec3780f00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Reading graph.tsv into graph dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/graph.tsv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'^Unnamed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Converting values to dictionary and to list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\malav\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\malav\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\malav\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\malav\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Reading graph.tsv into graph dataframe\n",
    "graph = pd.read_csv('../data/graph.tsv', sep='\\t')\n",
    "graph = graph.loc[:, ~graph.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Converting values to dictionary and to list\n",
    "graph['values'] = graph['values'].apply(lambda x: list(ast.literal_eval(x).items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exploding\n",
    "new_graph=graph.explode('values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-indexing \n",
    "new_graph[[\"to_node\", \"value\"]]= pd.DataFrame(new_graph[\"values\"].values.tolist(), index=new_graph.index)\n",
    "new_graph.drop(columns=[\"values\"], inplace=True)\n",
    "new_graph.set_index(keys=[\"key\", \"to_node\"], drop= True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all {}_actor.tsv intoa list of dataframes\n",
    "path = r'../data'\n",
    "all_files = glob.glob(path + \"/*_actor2.tsv\")\n",
    "li = [pd.read_csv(filename, sep=\"\\t\", header=0) for filename in all_files]\n",
    "\n",
    "# Collecting only the Actor_IDs\n",
    "IDs = [list(df[\"Actor ID\"]) for df in li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortest path between a and b on new_graph\n",
    "def relation_score(a,b,new_graph):\n",
    "    step = {\n",
    "        \"node\": a,\n",
    "        \"value\": 0,\n",
    "        \"distance\": 0,\n",
    "        \"values\": [],\n",
    "        \"cost\": 0,\n",
    "        \"prev\": \"\"\n",
    "    }\n",
    "\n",
    "    # This is all of the nodes we already found the shortest path to\n",
    "    finished = {}\n",
    "    # This is the next steps to consider\n",
    "    queue = [step]\n",
    "    # This is basically Dijkstra's shortest path algorithm\n",
    "    while len(queue) > 0:\n",
    "        # Take the node with the lowest cost\n",
    "        queue.sort(key=lambda x: x[\"cost\"], reverse=True)\n",
    "        current = queue.pop()\n",
    "        # When you take a node from the queue it means that you have found the shortest path to that node.\n",
    "        finished[current[\"node\"]] = current\n",
    "        #print(\"Looking at \" + current[\"node\"] + \", distance: \" + str(current[\"distance\"]) + \", cost: \" + str(current[\"cost\"]))\n",
    "        if current[\"node\"] == b:\n",
    "            break\n",
    "        # The distance to the next nodes is 1 more than the distance to this node\n",
    "        new_dist = current[\"distance\"] + 1\n",
    "        # Values is a list of the graph values so that we can calculate the average when we are calculating the cost\n",
    "        new_values = current[\"values\"]\n",
    "        # Find all of the edges from this node to it's neighbours as dict\n",
    "        edges = new_graph.loc[current[\"node\"]].to_dict()[\"value\"]\n",
    "        for edge in edges:\n",
    "            if finished.get(edge): continue\n",
    "            val = edges[edge]\n",
    "            vals = new_values + [val]\n",
    "            cost = 10 - (11 - new_dist + 10 - sum(vals) / new_dist) / 2\n",
    "\n",
    "            new_step = {\n",
    "                \"node\": edge,\n",
    "                \"value\": val,\n",
    "                \"distance\": new_dist,\n",
    "                \"values\": vals,\n",
    "                \"cost\": cost,\n",
    "                \"prev\": current[\"node\"]\n",
    "            }\n",
    "\n",
    "            in_queue = False\n",
    "            for i in range(len(queue)):\n",
    "                if queue[i][\"node\"] == edge:\n",
    "                    if queue[i][\"cost\"] > new_step[\"cost\"]:\n",
    "                        queue[i] = new_step\n",
    "                    in_queue = True\n",
    "                    break\n",
    "            if in_queue: continue\n",
    "            queue.append(new_step)\n",
    "\n",
    "    actor = b\n",
    "    path = []\n",
    "    while actor != \"\":\n",
    "        path.append(actor)\n",
    "        actor = finished[actor][\"prev\"]\n",
    "    path = list(reversed(path))\n",
    "    score = 10 - finished[b][\"cost\"]\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of the IDs from {}_actor.tsv with each other \n",
    "Id_list = list(itertools.product(*IDs))\n",
    "\n",
    "#Id_list as a dataframe\n",
    "data = pd.DataFrame(Id_list)\n",
    "\n",
    "#Computing scoresfor all combinations in Id_list as average of all {}_actors\n",
    "combs = []\n",
    "for i in range(0, len(IDs)):\n",
    "    for j in range(i+1, len(IDs)):\n",
    "        if i > 0:\n",
    "            print(\"ok\")\n",
    "        combs.extend([(x, y, relation_score(x, y, new_graph)) for x in IDs[i] for y in IDs[j]])\n",
    "\n",
    "\n",
    "#Making it to a dataframe\n",
    "d1 = pd.DataFrame(combs, columns=[\"ID1\", \"ID2\", \"Score\"])\n",
    "\n",
    "#Initialising r_score to 0\n",
    "data['r_score'] = 0.0\n",
    "\n",
    "#Iteratively merging {}_actors to data and summing score\n",
    "for i in range(len(li)):\n",
    "    for j in range(i, len(li)):\n",
    "        if (j + 1) < len(IDs):\n",
    "            data = pd.merge(data,d1, how='inner', left_on=[i, j + 1], right_on=['ID1', 'ID2'])\n",
    "            data['r_score'] = data['r_score'] + data['Score']\n",
    "            data = data.drop(['ID1','ID2','Score'], axis=1)\n",
    "\n",
    "\n",
    "#Finding average of r_score\n",
    "data['r_score'] = data['r_score'] / len(li)\n",
    "\n",
    "#Removing all zero scored values\n",
    "data = data.loc[(data['r_score'] != 0)]\n",
    "#Sorting \n",
    "data = data.sort_values(by='r_score', ascending=False)\n",
    "\n",
    "#Merging r_score and gs_score\n",
    "df = data\n",
    "for i in range(len(li)):\n",
    "    df = pd.merge(df, li[i], how='inner', left_on=i, right_on='Actor ID')\n",
    "    sname = 'score_{}'.format(i)\n",
    "    df[sname] = df['score']\n",
    "    df = df.drop(['Actor ID', 'Avg Genre Score', 'summary_score', 'score'], axis=1)\n",
    "\n",
    "#Finding mean of the gs_score of the {}_actors \n",
    "sname = []\n",
    "for i in range(len(li)):\n",
    "    sname.append('score_{}'.format(i))\n",
    "col = df.loc[:, sname]\n",
    "df['gs_score'] = col.mean(axis=1)\n",
    "\n",
    "#Finding average of the r_score and gs_score and making the final list\n",
    "df['final'] = df[[\"r_score\",\"gs_score\"]].mean(axis=1)\n",
    "col_list = list(range(len(li)))\n",
    "col_list.append('final')\n",
    "final_df = df[col_list]\n",
    "final_df = final_df.sort_values(by='final', ascending=False)\n",
    "\n",
    "#Outputting the final list as a tsv\n",
    "final_df.to_csv('../data/final2_jupy.tsv', sep= '\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
